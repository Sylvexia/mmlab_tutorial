# 後話

## openmmlab適合什麼樣的的人?

以目前來看，openmmlab最適合打各種物件偵測比賽的人，其統一的界面，接口可以快速替換模型的backbone，loss等等。對於物件偵測演算法非常熟悉的人想要快速的玩各種演算法的人。

## 推不推薦使用openmmlab?

openmmlab目前來看，看起來最強的是演算法層面，在應用層面個人覺得滿糟糕的。以最簡單的取得偵測結果來看(知道什麼物件在哪個像素點上等等），openmmlab甚至沒有這個api接口，只有畫在畫面上。訓練完之後的模型要做部屬（如部屬到板子上），以及有效率的成功運行在板子（如藉由jetson nx上面的tensorrt加速得得到更好的framerate），會需要花額外的功夫。不會比自己在jetson官方給的物件偵測模型實作還要容易。

若是大學生而言，大多數只是應用一個簡單的物件偵測模型，其最主要的目的就是能用就好，如果要學物件偵測還是圖像相關的深度學習的話，建議不要花時間在這個上面，而是先學完pytorch，若是對於詳細的物件偵測的演算法這個層面有興趣再來學習。依照個人只對於應用層面有著墨的話，基本上出了換模型這件事情很好玩之外，沒有太大的幫助。

若是研究或學術層面的話，我個人覺得是以快速展示模型的prototype為主，如果懂得一些深度模型的知識，要做各種模型的簡單更動是超級快速的。但實際上根據我使用的情況來說，有一些模型也不是馬上下載下來就可以馬上使用的。有的時候在自己電腦測試會因為兩個原因而有一些困難：1. 這個模型本身是在分散式做模型訓練的，需要更改一些參數或需要更好的顯卡才能運行。2. 我本身對於深度模型的背景知識太過貧乏。有東西出事我不知道也難以查詢，也在github上看到許多人和自己同樣踩了不少坑，甚至也沒有找到相對映的解決方案。此外在是否支援最新的演算法上，可能也需要一段時間才會有相對應的實現，至於藉由mmdet的架構開發出來的演算法和原本的實現上是否有有落差，這個也是有人反應過的問題。

## 個人心得

物件偵測演算法需要一些專業知識才好去除錯以及更動，不能全部都用軟體工程的方法下去思考，這樣是拿鐵鎚去敲打螺絲一樣，不切實際。在物件偵測演算法層面上，我個人的知識不夠完整，因此能玩的東西最多也只是loss更換，調整學習率，在更深入的東西我再繼續專研依照目前的情況也是尋然未果。在加上自己在比賽之後要償還現實債（如課業、家人、自身狀況）也算是雪上加霜。在時間不夠，有其他事情優先的情況之下，研究這件事情的優先順序就被擺到很後面，甚至必須承認老師提了deadline的時候，我才把之前研究的東西做結案。因此深入的研究，如框架本身如何把各個部份做封裝、如何自定義演算法、如何部署，這幾件事情也沒有研究的太透徹或是一個成果，沒有十足把握，也就沒有放上來了，之後如果有需要研究深度學習的演算法的話，至少自己就有了一個toolbox可以做運用（不過機率蠻低的，未來研究所我是做compiler的）。最後希望四下自己能夠調整好自己的狀態，也祝福實驗室在研究上能夠順利的不斷有新的突破！

Peace！

Sylvex Hung, 洪祐鈞
2023-1-18